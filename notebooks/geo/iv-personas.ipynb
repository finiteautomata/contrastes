{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geolocalización con Information Value Personas\n",
    "\n",
    "En esta notebook haremos un intento de geolocalización con los textos de los usuarios..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_json(\"../data/geoloc/users_train.json\")\n",
    "df_test = pd.read_json(\"../data/geoloc/users_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo siguiente:\n",
    "\n",
    "- Entrenemos con unigramas una regresión logística para \n",
    "- Luego probemos con los regionalismos\n",
    "\n",
    "Primero, partamos en train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provincia</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buenosaires</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catamarca</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chaco</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chubut</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cordoba</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corrientes</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrerios</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formosa</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jujuy</th>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lapampa</th>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larioja</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mendoza</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misiones</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuquen</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rionegro</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salta</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanjuan</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanluis</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santacruz</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santafe</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santiago</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tierradelfuego</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tucuman</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "provincia           \n",
       "buenosaires      337\n",
       "catamarca        341\n",
       "chaco            331\n",
       "chubut           328\n",
       "cordoba          317\n",
       "corrientes       345\n",
       "entrerios        338\n",
       "formosa          286\n",
       "jujuy            339\n",
       "lapampa          324\n",
       "larioja          306\n",
       "mendoza          326\n",
       "misiones         327\n",
       "neuquen          350\n",
       "rionegro         313\n",
       "salta            346\n",
       "sanjuan          326\n",
       "sanluis          321\n",
       "santacruz        288\n",
       "santafe          347\n",
       "santiago         294\n",
       "tierradelfuego   332\n",
       "tucuman          338"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"provincia\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras precalculadas\n",
    "\n",
    "Carguemos antes las palabras que sabemos que ocurren una cantidad razonable de veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 704 ms, sys: 68 ms, total: 772 ms\n",
      "Wall time: 770 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/projects/contrastes/contrastes/processing.py:185: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_palabras = cant_palabras\n",
      "/home/jmperez/projects/contrastes/contrastes/processing.py:186: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_personas = cant_personas\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.processing import build_dataframe_from_users\n",
    "from contrastes.processing import preprocess_raw_df\n",
    "\n",
    "\n",
    "#word_df = build_dataframe_from_users(row for index, row in df_train.iterrows())\n",
    "\n",
    "word_df = pd.read_csv(\"train_word_df_filtered.csv\", index_col=0)\n",
    "word_df = preprocess_raw_df(word_df, filter_words=(10, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La reg. logística será un softmax, así que elijo `multi_class='multinomial'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating information values...\n",
      "Calculating ranks...\n"
     ]
    }
   ],
   "source": [
    "from contrastes.lists import add_ival\n",
    "\n",
    "add_ival(word_df, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buenosaires_ocurrencias</th>\n",
       "      <th>buenosaires_usuarios</th>\n",
       "      <th>catamarca_ocurrencias</th>\n",
       "      <th>catamarca_usuarios</th>\n",
       "      <th>chaco_ocurrencias</th>\n",
       "      <th>chaco_usuarios</th>\n",
       "      <th>chubut_ocurrencias</th>\n",
       "      <th>chubut_usuarios</th>\n",
       "      <th>cordoba_ocurrencias</th>\n",
       "      <th>cordoba_usuarios</th>\n",
       "      <th>...</th>\n",
       "      <th>tucuman_usuarios</th>\n",
       "      <th>cant_provincias</th>\n",
       "      <th>cant_palabra</th>\n",
       "      <th>cant_usuarios</th>\n",
       "      <th>ival_palabras</th>\n",
       "      <th>ival_personas</th>\n",
       "      <th>ival_palper</th>\n",
       "      <th>rank_palabras</th>\n",
       "      <th>rank_personas</th>\n",
       "      <th>rank_palper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>638.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>1.241734</td>\n",
       "      <td>1.612927</td>\n",
       "      <td>2.002826</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1.059592</td>\n",
       "      <td>1.584212</td>\n",
       "      <td>1.678618</td>\n",
       "      <td>117.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chivil</th>\n",
       "      <td>332.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>332.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.207573</td>\n",
       "      <td>1.574520</td>\n",
       "      <td>1.901348</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plottier</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>848.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1.387099</td>\n",
       "      <td>1.570455</td>\n",
       "      <td>2.178376</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chivilcoy</th>\n",
       "      <td>2331.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.599973</td>\n",
       "      <td>1.569203</td>\n",
       "      <td>2.510682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vallerga</th>\n",
       "      <td>291.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>291.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.180154</td>\n",
       "      <td>1.545664</td>\n",
       "      <td>1.824121</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yarca</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.055728</td>\n",
       "      <td>1.545184</td>\n",
       "      <td>1.631294</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolhuin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>373.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.184478</td>\n",
       "      <td>1.534011</td>\n",
       "      <td>1.817002</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>321.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1.033974</td>\n",
       "      <td>1.532793</td>\n",
       "      <td>1.584868</td>\n",
       "      <td>145.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malpegue</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>264.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.128838</td>\n",
       "      <td>1.523059</td>\n",
       "      <td>1.719288</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           buenosaires_ocurrencias  buenosaires_usuarios  \\\n",
       "ush                            0.0                   0.0   \n",
       "poec                           0.0                   0.0   \n",
       "chivil                       332.0                  79.0   \n",
       "plottier                       0.0                   0.0   \n",
       "chivilcoy                   2331.0                 125.0   \n",
       "vallerga                     291.0                  72.0   \n",
       "yarca                          0.0                   0.0   \n",
       "tolhuin                        0.0                   0.0   \n",
       "fsa                            0.0                   0.0   \n",
       "malpegue                       0.0                   0.0   \n",
       "\n",
       "           catamarca_ocurrencias  catamarca_usuarios  chaco_ocurrencias  \\\n",
       "ush                          0.0                 0.0                0.0   \n",
       "poec                         0.0                 0.0                0.0   \n",
       "chivil                       0.0                 0.0                0.0   \n",
       "plottier                     0.0                 0.0                0.0   \n",
       "chivilcoy                    0.0                 0.0                1.0   \n",
       "vallerga                     0.0                 0.0                0.0   \n",
       "yarca                        0.0                 0.0                0.0   \n",
       "tolhuin                      0.0                 0.0                0.0   \n",
       "fsa                          0.0                 0.0               22.0   \n",
       "malpegue                     0.0                 0.0                0.0   \n",
       "\n",
       "           chaco_usuarios  chubut_ocurrencias  chubut_usuarios  \\\n",
       "ush                   0.0                 1.0              1.0   \n",
       "poec                  0.0                 0.0              0.0   \n",
       "chivil                0.0                 0.0              0.0   \n",
       "plottier              0.0                 1.0              1.0   \n",
       "chivilcoy             1.0                 0.0              0.0   \n",
       "vallerga              0.0                 0.0              0.0   \n",
       "yarca                 0.0                 0.0              0.0   \n",
       "tolhuin               0.0                 1.0              1.0   \n",
       "fsa                   2.0                 0.0              0.0   \n",
       "malpegue              0.0                 0.0              0.0   \n",
       "\n",
       "           cordoba_ocurrencias  cordoba_usuarios     ...       \\\n",
       "ush                        0.0               0.0     ...        \n",
       "poec                       0.0               0.0     ...        \n",
       "chivil                     0.0               0.0     ...        \n",
       "plottier                   0.0               0.0     ...        \n",
       "chivilcoy                  1.0               1.0     ...        \n",
       "vallerga                   0.0               0.0     ...        \n",
       "yarca                      0.0               0.0     ...        \n",
       "tolhuin                    0.0               0.0     ...        \n",
       "fsa                        4.0               1.0     ...        \n",
       "malpegue                   0.0               0.0     ...        \n",
       "\n",
       "           tucuman_usuarios  cant_provincias  cant_palabra  cant_usuarios  \\\n",
       "ush                     0.0                6         638.0          346.0   \n",
       "poec                    0.0                1         163.0          164.0   \n",
       "chivil                  0.0                1         332.0          158.0   \n",
       "plottier                0.0                3         848.0          206.0   \n",
       "chivilcoy               0.0                6        2337.0          262.0   \n",
       "vallerga                0.0                1         291.0          144.0   \n",
       "yarca                   0.0                1         160.0          142.0   \n",
       "tolhuin                 0.0                5         373.0          200.0   \n",
       "fsa                     0.0                6         321.0          232.0   \n",
       "malpegue                0.0                3         264.0          170.0   \n",
       "\n",
       "           ival_palabras  ival_personas  ival_palper  rank_palabras  \\\n",
       "ush             1.241734       1.612927     2.002826           37.0   \n",
       "poec            1.059592       1.584212     1.678618          117.5   \n",
       "chivil          1.207573       1.574520     1.901348           46.0   \n",
       "plottier        1.387099       1.570455     2.178376           14.0   \n",
       "chivilcoy       1.599973       1.569203     2.510682            4.0   \n",
       "vallerga        1.180154       1.545664     1.824121           59.0   \n",
       "yarca           1.055728       1.545184     1.631294          120.0   \n",
       "tolhuin         1.184478       1.534011     1.817002           57.0   \n",
       "fsa             1.033974       1.532793     1.584868          145.0   \n",
       "malpegue        1.128838       1.523059     1.719288           77.0   \n",
       "\n",
       "           rank_personas  rank_palper  \n",
       "ush                  1.0          4.0  \n",
       "poec                 2.0         18.0  \n",
       "chivil               3.0          6.0  \n",
       "plottier             4.0          3.0  \n",
       "chivilcoy            5.0          1.0  \n",
       "vallerga             6.0          8.0  \n",
       "yarca                7.0         23.0  \n",
       "tolhuin              8.0          9.0  \n",
       "fsa                  9.0         26.0  \n",
       "malpegue            10.0         16.0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.sort_values(\"rank_personas\", ascending=True, inplace=True)\n",
    "\n",
    "word_df.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué performance tiene usando 1000, 2000, 3000, y así..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing\n",
      "CPU times: user 9min 44s, sys: 556 ms, total: 9min 45s\n",
      "Wall time: 9min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from contrastes.text import tokenize\n",
    "\n",
    "liw_vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    vocabulary=word_df.index)\n",
    "\n",
    "X_train = liw_vectorizer.fit_transform(df_train[\"text\"])\n",
    "print(\"Vectorizing\")\n",
    "X_test = liw_vectorizer.transform(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya las tenemos vectorizadas en el orden esperado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "province_encoder = LabelEncoder()\n",
    "\n",
    "province_encoder.fit(df_train[\"provincia\"].values)\n",
    "\n",
    "y_train = province_encoder.transform(df_train[\"provincia\"].values)\n",
    "y_test = province_encoder.transform(df_test[\"provincia\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier params: {'multi_class': 'multinomial', 'solver': 'saga', 'penalty': 'l2', 'max_iter': 7000}\n",
      "Entrenando con 750 palabras\n",
      "Entrenando con 250 palabras\n",
      "Entrenando con 1250 palabras\n",
      "Entrenando con 2250 palabras\n",
      "Entrenando con 2750 palabras\n",
      "Entrenando con 3250 palabras\n",
      "Entrenando con 3750 palabras\n",
      "Entrenando con 1750 palabras\n",
      "Entrenando con 4750 palabras\n",
      "Entrenando con 4250 palabras\n",
      "250   palabras ----> accuracy 59.48 mean distance 306.7484\n",
      "Entrenando con 500 palabras\n",
      "750   palabras ----> accuracy 69.60 mean distance 232.472\n",
      "Entrenando con 1000 palabras\n",
      "1250  palabras ----> accuracy 73.80 mean distance 228.4808\n",
      "Entrenando con 1500 palabras\n",
      "1750  palabras ----> accuracy 76.20 mean distance 207.0176\n",
      "Entrenando con 2000 palabras\n",
      "2750  palabras ----> accuracy 76.56 mean distance 196.4944\n",
      "Entrenando con 3000 palabras\n",
      "2250  palabras ----> accuracy 76.12 mean distance 186.1324\n",
      "Entrenando con 2500 palabras\n",
      "3250  palabras ----> accuracy 77.16 mean distance 178.4376\n",
      "Entrenando con 3500 palabras\n",
      "4250  palabras ----> accuracy 78.76 mean distance 166.3432\n",
      "Entrenando con 4500 palabras\n",
      "3750  palabras ----> accuracy 78.16 mean distance 172.1536\n",
      "Entrenando con 4000 palabras\n",
      "4750  palabras ----> accuracy 78.36 mean distance 164.2072\n",
      "Entrenando con 5000 palabras\n",
      "500   palabras ----> accuracy 67.24 mean distance 253.02\n",
      "Entrenando con 5500 palabras\n",
      "1000  palabras ----> accuracy 71.96 mean distance 245.748\n",
      "Entrenando con 6500 palabras\n",
      "1500  palabras ----> accuracy 74.72 mean distance 218.8384\n",
      "Entrenando con 7500 palabras\n",
      "2000  palabras ----> accuracy 76.28 mean distance 203.7484\n",
      "Entrenando con 8500 palabras\n",
      "3000  palabras ----> accuracy 77.00 mean distance 179.2064\n",
      "Entrenando con 9500 palabras\n",
      "2500  palabras ----> accuracy 76.16 mean distance 184.4612\n",
      "Entrenando con 10500 palabras\n",
      "3500  palabras ----> accuracy 78.12 mean distance 171.3148\n",
      "Entrenando con 11500 palabras\n",
      "4000  palabras ----> accuracy 78.56 mean distance 168.8024\n",
      "Entrenando con 12500 palabras\n",
      "4500  palabras ----> accuracy 78.64 mean distance 167.136\n",
      "Entrenando con 13500 palabras\n",
      "5000  palabras ----> accuracy 78.40 mean distance 164.8808\n",
      "Entrenando con 14500 palabras\n",
      "5500  palabras ----> accuracy 78.76 mean distance 168.7732\n",
      "Entrenando con 6000 palabras\n",
      "6500  palabras ----> accuracy 78.52 mean distance 170.82\n",
      "Entrenando con 7000 palabras\n",
      "7500  palabras ----> accuracy 78.84 mean distance 169.63\n",
      "Entrenando con 8000 palabras\n",
      "8500  palabras ----> accuracy 78.84 mean distance 169.038\n",
      "Entrenando con 9000 palabras\n",
      "9500  palabras ----> accuracy 79.00 mean distance 168.1424\n",
      "Entrenando con 10000 palabras\n",
      "6000  palabras ----> accuracy 78.32 mean distance 171.5208\n",
      "Entrenando con 15500 palabras\n",
      "10500 palabras ----> accuracy 79.20 mean distance 169.73\n",
      "Entrenando con 11000 palabras\n",
      "11500 palabras ----> accuracy 79.64 mean distance 168.4848\n",
      "Entrenando con 12000 palabras\n",
      "7000  palabras ----> accuracy 78.48 mean distance 171.9928\n",
      "Entrenando con 16500 palabras\n",
      "8000  palabras ----> accuracy 79.04 mean distance 168.394\n",
      "Entrenando con 17500 palabras\n",
      "12500 palabras ----> accuracy 77.56 mean distance 184.9516\n",
      "Entrenando con 13000 palabras\n",
      "13500 palabras ----> accuracy 77.56 mean distance 184.0828\n",
      "Entrenando con 14000 palabras\n",
      "9000  palabras ----> accuracy 78.84 mean distance 169.7656\n",
      "Entrenando con 18500 palabras\n",
      "14500 palabras ----> accuracy 77.68 mean distance 184.7344\n",
      "Entrenando con 15000 palabras\n",
      "10000 palabras ----> accuracy 79.08 mean distance 169.236\n",
      "Entrenando con 19500 palabras\n",
      "11000 palabras ----> accuracy 79.36 mean distance 169.4032\n",
      "12000 palabras ----> accuracy 79.60 mean distance 169.4724\n",
      "15500 palabras ----> accuracy 78.16 mean distance 174.568\n",
      "Entrenando con 16000 palabras\n",
      "13000 palabras ----> accuracy 77.60 mean distance 184.7668\n",
      "16500 palabras ----> accuracy 78.20 mean distance 173.8032\n",
      "Entrenando con 17000 palabras\n",
      "14000 palabras ----> accuracy 77.64 mean distance 184.2232\n",
      "15000 palabras ----> accuracy 78.36 mean distance 175.5008\n",
      "17500 palabras ----> accuracy 78.12 mean distance 174.3052\n",
      "Entrenando con 18000 palabras\n",
      "18500 palabras ----> accuracy 78.24 mean distance 172.6432\n",
      "Entrenando con 19000 palabras\n",
      "19500 palabras ----> accuracy 78.16 mean distance 171.4808\n",
      "16000 palabras ----> accuracy 78.12 mean distance 174.2748\n",
      "17000 palabras ----> accuracy 78.20 mean distance 174.2464\n",
      "18000 palabras ----> accuracy 78.04 mean distance 174.8376\n",
      "19000 palabras ----> accuracy 78.16 mean distance 170.056\n",
      "CPU times: user 1.28 s, sys: 1.24 s, total: 2.52 s\n",
      "Wall time: 23min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.classifiers import fit_classifiers\n",
    "\n",
    "num_words_to_fit = list(range(250, 5000, 250)) + list(range(5000, 20000, 500))\n",
    "\n",
    "params = {\"max_iter\": 7000}\n",
    "\n",
    "ret = fit_classifiers(X_train, y_train, X_test, y_test, \n",
    "                      province_encoder=province_encoder, clf_params=params,\n",
    "                      range_num_words=num_words_to_fit, num_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250   palabras ----> accuracy 59.48 mean distance 306.7484\n",
      "500   palabras ----> accuracy 67.24 mean distance 253.02\n",
      "750   palabras ----> accuracy 69.60 mean distance 232.472\n",
      "1000  palabras ----> accuracy 71.96 mean distance 245.748\n",
      "1250  palabras ----> accuracy 73.80 mean distance 228.4808\n",
      "1500  palabras ----> accuracy 74.72 mean distance 218.8384\n",
      "1750  palabras ----> accuracy 76.20 mean distance 207.0176\n",
      "2000  palabras ----> accuracy 76.28 mean distance 203.7484\n",
      "2250  palabras ----> accuracy 76.12 mean distance 186.1324\n",
      "2500  palabras ----> accuracy 76.16 mean distance 184.4612\n",
      "2750  palabras ----> accuracy 76.56 mean distance 196.4944\n",
      "3000  palabras ----> accuracy 77.00 mean distance 179.2064\n",
      "3250  palabras ----> accuracy 77.16 mean distance 178.4376\n",
      "3500  palabras ----> accuracy 78.12 mean distance 171.3148\n",
      "3750  palabras ----> accuracy 78.16 mean distance 172.1536\n",
      "4000  palabras ----> accuracy 78.56 mean distance 168.8024\n",
      "4250  palabras ----> accuracy 78.76 mean distance 166.3432\n",
      "4500  palabras ----> accuracy 78.64 mean distance 167.136\n",
      "4750  palabras ----> accuracy 78.36 mean distance 164.2072\n",
      "5000  palabras ----> accuracy 78.40 mean distance 164.8808\n",
      "5500  palabras ----> accuracy 78.76 mean distance 168.7732\n",
      "6000  palabras ----> accuracy 78.32 mean distance 171.5208\n",
      "6500  palabras ----> accuracy 78.52 mean distance 170.82\n",
      "7000  palabras ----> accuracy 78.48 mean distance 171.9928\n",
      "7500  palabras ----> accuracy 78.84 mean distance 169.63\n",
      "8000  palabras ----> accuracy 79.04 mean distance 168.394\n",
      "8500  palabras ----> accuracy 78.84 mean distance 169.038\n",
      "9000  palabras ----> accuracy 78.84 mean distance 169.7656\n",
      "9500  palabras ----> accuracy 79.00 mean distance 168.1424\n",
      "10000 palabras ----> accuracy 79.08 mean distance 169.236\n",
      "10500 palabras ----> accuracy 79.20 mean distance 169.73\n",
      "11000 palabras ----> accuracy 79.36 mean distance 169.4032\n",
      "11500 palabras ----> accuracy 79.64 mean distance 168.4848\n",
      "12000 palabras ----> accuracy 79.60 mean distance 169.4724\n",
      "12500 palabras ----> accuracy 77.56 mean distance 184.9516\n",
      "13000 palabras ----> accuracy 77.60 mean distance 184.7668\n",
      "13500 palabras ----> accuracy 77.56 mean distance 184.0828\n",
      "14000 palabras ----> accuracy 77.64 mean distance 184.2232\n",
      "14500 palabras ----> accuracy 77.68 mean distance 184.7344\n",
      "15000 palabras ----> accuracy 78.36 mean distance 175.5008\n",
      "15500 palabras ----> accuracy 78.16 mean distance 174.568\n",
      "16000 palabras ----> accuracy 78.12 mean distance 174.2748\n",
      "16500 palabras ----> accuracy 78.20 mean distance 173.8032\n",
      "17000 palabras ----> accuracy 78.20 mean distance 174.2464\n",
      "17500 palabras ----> accuracy 78.12 mean distance 174.3052\n",
      "18000 palabras ----> accuracy 78.04 mean distance 174.8376\n",
      "18500 palabras ----> accuracy 78.24 mean distance 172.6432\n",
      "19000 palabras ----> accuracy 78.16 mean distance 170.056\n",
      "19500 palabras ----> accuracy 78.16 mean distance 171.4808\n"
     ]
    }
   ],
   "source": [
    "for r in ret:\n",
    "    num_words = r[\"num_words\"]\n",
    "    acc = r[\"accuracy\"]\n",
    "    md = r[\"mean_distance\"]\n",
    "    print(\"{:<5} palabras ----> accuracy {:.2f} mean distance {}\".format(\n",
    "        num_words, acc*100, md\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(ret, open(\"res_iv_personas.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
