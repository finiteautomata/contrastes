{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geolocalización con TF-IPF\n",
    "\n",
    "En esta notebook haremos un intento de geolocalización con los textos de los usuarios.\n",
    "\n",
    "Pero haremos algo distinto: usaremos Term Frequency - Inverse Province Frequency (TF-IPF)\n",
    "\n",
    "\n",
    "[Geolocation prediction in social media data by finding location indicative words](http://www.aclweb.org/anthology/C12-1064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_json(\"../data/geoloc/users_train.json\")\n",
    "df_test = pd.read_json(\"../data/geoloc/users_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo siguiente:\n",
    "\n",
    "- Entrenemos con unigramas una regresión logística para \n",
    "- Luego probemos con los regionalismos\n",
    "\n",
    "Primero, partamos en train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provincia</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buenosaires</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catamarca</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chaco</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chubut</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cordoba</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corrientes</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrerios</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formosa</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jujuy</th>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lapampa</th>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larioja</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mendoza</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misiones</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuquen</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rionegro</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salta</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanjuan</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanluis</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santacruz</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santafe</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santiago</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tierradelfuego</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tucuman</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "provincia           \n",
       "buenosaires      337\n",
       "catamarca        341\n",
       "chaco            331\n",
       "chubut           328\n",
       "cordoba          317\n",
       "corrientes       345\n",
       "entrerios        338\n",
       "formosa          286\n",
       "jujuy            339\n",
       "lapampa          324\n",
       "larioja          306\n",
       "mendoza          326\n",
       "misiones         327\n",
       "neuquen          350\n",
       "rionegro         313\n",
       "salta            346\n",
       "sanjuan          326\n",
       "sanluis          321\n",
       "santacruz        288\n",
       "santafe          347\n",
       "santiago         294\n",
       "tierradelfuego   332\n",
       "tucuman          338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"provincia\").count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras precalculadas\n",
    "\n",
    "Carguemos antes las palabras que sabemos que ocurren una cantidad razonable de veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 140 ms, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/projects/contrastes/contrastes/processing.py:185: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_palabras = cant_palabras\n",
      "/home/jmperez/projects/contrastes/contrastes/processing.py:186: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_personas = cant_personas\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.processing import build_dataframe_from_users\n",
    "from contrastes.processing import preprocess_raw_df\n",
    "\n",
    "\n",
    "#word_df = build_dataframe_from_users(row for index, row in df_train.iterrows())\n",
    "\n",
    "word_df = pd.read_csv(\"train_word_df_filtered.csv\", index_col=0)\n",
    "word_df = preprocess_raw_df(word_df, filter_words=(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_palabra</th>\n",
       "      <th>cant_provincias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tiemposur</th>\n",
       "      <td>883.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logroño</th>\n",
       "      <td>711.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nihuil</th>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chivil</th>\n",
       "      <td>332.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipauss</th>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vallerga</th>\n",
       "      <td>291.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asprodema</th>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdelu</th>\n",
       "      <td>244.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calahorra</th>\n",
       "      <td>216.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canicross</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cant_palabra  cant_provincias\n",
       "tiemposur         883.0                1\n",
       "logroño           711.0                1\n",
       "nihuil            450.0                1\n",
       "chivil            332.0                1\n",
       "ipauss            315.0                1\n",
       "vallerga          291.0                1\n",
       "asprodema         290.0                1\n",
       "cdelu             244.0                1\n",
       "calahorra         216.0                1\n",
       "canicross         202.0                1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.sort_values([\"cant_provincias\", \"cant_palabra\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "word_df.iloc[:10][[\"cant_palabra\", \"cant_provincias\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué performance tiene usando 1000, 2000, 3000, y así..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing\n",
      "CPU times: user 9min 22s, sys: 928 ms, total: 9min 23s\n",
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from contrastes.text import tokenize\n",
    "\n",
    "liw_vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    vocabulary=word_df.index)\n",
    "\n",
    "X_train = liw_vectorizer.fit_transform(df_train[\"text\"])\n",
    "print(\"Vectorizing\")\n",
    "X_test = liw_vectorizer.transform(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya las tenemos vectorizadas en el orden esperado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Save an array to a binary file in NumPy ``.npy`` format.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "file : file, str, or pathlib.Path\n",
       "    File or filename to which the data is saved.  If file is a file-object,\n",
       "    then the filename is unchanged.  If file is a string or Path, a ``.npy``\n",
       "    extension will be appended to the file name if it does not already\n",
       "    have one.\n",
       "arr : array_like\n",
       "    Array data to be saved.\n",
       "allow_pickle : bool, optional\n",
       "    Allow saving object arrays using Python pickles. Reasons for disallowing\n",
       "    pickles include security (loading pickled data can execute arbitrary\n",
       "    code) and portability (pickled objects may not be loadable on different\n",
       "    Python installations, for example if the stored objects require libraries\n",
       "    that are not available, and not all pickled data is compatible between\n",
       "    Python 2 and Python 3).\n",
       "    Default: True\n",
       "fix_imports : bool, optional\n",
       "    Only useful in forcing objects in object arrays on Python 3 to be\n",
       "    pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n",
       "    will try to map the new Python 3 names to the old module names used in\n",
       "    Python 2, so that the pickle data stream is readable with Python 2.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "savez : Save several arrays into a ``.npz`` archive\n",
       "savetxt, load\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For a description of the ``.npy`` format, see the module docstring\n",
       "of `numpy.lib.format` or the NumPy Enhancement Proposal\n",
       "http://docs.scipy.org/doc/numpy/neps/npy-format.html\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from tempfile import TemporaryFile\n",
       ">>> outfile = TemporaryFile()\n",
       "\n",
       ">>> x = np.arange(10)\n",
       ">>> np.save(outfile, x)\n",
       "\n",
       ">>> outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
       ">>> np.load(outfile)\n",
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/numpy/lib/npyio.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con 6500 palabras\n",
      "Entrenando con 7500 palabras\n",
      "Entrenando con 8500 palabras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(open(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "province_encoder = LabelEncoder()\n",
    "\n",
    "province_encoder.fit(df_train[\"provincia\"].values)\n",
    "\n",
    "y_train = province_encoder.transform(df_train[\"provincia\"].values)\n",
    "y_test = province_encoder.transform(df_test[\"provincia\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier params: {'multi_class': 'multinomial', 'solver': 'saga', 'penalty': 'l2', 'max_iter': 7000}\n",
      "Entrenando con 250 palabras\n",
      "Entrenando con 2250 palabras\n",
      "Entrenando con 1750 palabras\n",
      "Entrenando con 750 palabras\n",
      "Entrenando con 1250 palabras\n",
      "Entrenando con 2750 palabras\n",
      "Entrenando con 3750 palabras\n",
      "Entrenando con 3250 palabras\n",
      "250   palabras ----> accuracy 25.12 mean distance 750.3752\n",
      "Entrenando con 500 palabras\n",
      "750   palabras ----> accuracy 35.24 mean distance 643.978\n",
      "Entrenando con 1000 palabras\n",
      "1250  palabras ----> accuracy 44.24 mean distance 568.6348\n",
      "Entrenando con 1500 palabras\n",
      "1750  palabras ----> accuracy 51.92 mean distance 496.7968\n",
      "Entrenando con 2000 palabras\n",
      "2750  palabras ----> accuracy 57.28 mean distance 438.098\n",
      "Entrenando con 3000 palabras\n",
      "2250  palabras ----> accuracy 53.72 mean distance 475.3536\n",
      "Entrenando con 2500 palabras\n",
      "3250  palabras ----> accuracy 60.12 mean distance 419.0848\n",
      "Entrenando con 3500 palabras\n",
      "3750  palabras ----> accuracy 61.00 mean distance 402.1748\n",
      "Entrenando con 4000 palabras\n",
      "500   palabras ----> accuracy 31.92 mean distance 676.392\n",
      "Entrenando con 4250 palabras\n",
      "1000  palabras ----> accuracy 38.56 mean distance 614.062\n",
      "Entrenando con 4750 palabras\n",
      "1500  palabras ----> accuracy 49.32 mean distance 516.4276\n",
      "Entrenando con 5500 palabras\n",
      "2000  palabras ----> accuracy 53.00 mean distance 484.152\n",
      "Entrenando con 6500 palabras\n",
      "3000  palabras ----> accuracy 59.12 mean distance 424.4572\n",
      "Entrenando con 7500 palabras\n",
      "2500  palabras ----> accuracy 55.08 mean distance 462.016\n",
      "Entrenando con 8500 palabras\n",
      "3500  palabras ----> accuracy 60.68 mean distance 411.8884\n",
      "Entrenando con 9500 palabras\n",
      "4000  palabras ----> accuracy 61.28 mean distance 396.7428\n",
      "Entrenando con 10500 palabras\n",
      "4250  palabras ----> accuracy 63.44 mean distance 352.6272\n",
      "Entrenando con 4500 palabras\n",
      "4750  palabras ----> accuracy 65.52 mean distance 361.4596\n",
      "Entrenando con 5000 palabras\n",
      "5500  palabras ----> accuracy 65.40 mean distance 363.0488\n",
      "Entrenando con 6000 palabras\n",
      "6500  palabras ----> accuracy 67.52 mean distance 320.4984\n",
      "Entrenando con 7000 palabras\n",
      "7500  palabras ----> accuracy 67.52 mean distance 316.7936\n",
      "Entrenando con 8000 palabras\n",
      "4500  palabras ----> accuracy 64.20 mean distance 344.946\n",
      "Entrenando con 11500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500  palabras ----> accuracy 68.24 mean distance 282.8416\n",
      "Entrenando con 9000 palabras\n",
      "5000  palabras ----> accuracy 65.44 mean distance 363.3788\n",
      "Entrenando con 12500 palabras\n",
      "6000  palabras ----> accuracy 67.40 mean distance 325.9384\n",
      "Entrenando con 13500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500  palabras ----> accuracy 68.44 mean distance 280.7484\n",
      "Entrenando con 10000 palabras\n",
      "7000  palabras ----> accuracy 67.52 mean distance 319.4756\n",
      "Entrenando con 14500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500 palabras ----> accuracy 68.48 mean distance 281.9504\n",
      "Entrenando con 11000 palabras\n",
      "8000  palabras ----> accuracy 67.64 mean distance 315.458\n",
      "Entrenando con 15500 palabras\n",
      "9000  palabras ----> accuracy 68.40 mean distance 280.7088\n",
      "Entrenando con 16500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500 palabras ----> accuracy 69.36 mean distance 272.6472\n",
      "Entrenando con 12000 palabras\n",
      "10000 palabras ----> accuracy 68.44 mean distance 281.9068\n",
      "Entrenando con 17500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 palabras ----> accuracy 69.80 mean distance 269.2596\n",
      "Entrenando con 13000 palabras\n",
      "11000 palabras ----> accuracy 68.56 mean distance 282.1152\n",
      "Entrenando con 18500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500 palabras ----> accuracy 69.84 mean distance 272.1724\n",
      "Entrenando con 14000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500 palabras ----> accuracy 69.92 mean distance 270.7404\n",
      "Entrenando con 15000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15500 palabras ----> accuracy 69.80 mean distance 272.006\n",
      "Entrenando con 16000 palabras\n",
      "12000 palabras ----> accuracy 69.60 mean distance 272.0088\n",
      "Entrenando con 19500 palabras\n",
      "13000 palabras ----> accuracy 69.80 mean distance 270.3984\n",
      "16500 palabras ----> accuracy 70.08 mean distance 270.608\n",
      "Entrenando con 17000 palabras\n",
      "14000 palabras ----> accuracy 69.88 mean distance 272.28\n",
      "15000 palabras ----> accuracy 69.92 mean distance 271.1168\n",
      "18500 palabras ----> accuracy 70.20 mean distance 271.2784\n",
      "Entrenando con 19000 palabras\n",
      "16000 palabras ----> accuracy 69.72 mean distance 270.9292\n",
      "19500 palabras ----> accuracy 70.32 mean distance 270.548\n",
      "17000 palabras ----> accuracy 70.12 mean distance 270.9364\n",
      "18000 palabras ----> accuracy 70.16 mean distance 270.6296\n",
      "19000 palabras ----> accuracy 70.36 mean distance 270.8848\n",
      "CPU times: user 2.5 s, sys: 1.71 s, total: 4.21 s\n",
      "Wall time: 26min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.classifiers import fit_classifiers\n",
    "\n",
    "num_words_to_fit = list(range(250, 5000, 250)) + list(range(5000, 20000, 500))\n",
    "\n",
    "params = {\"max_iter\": 7000}\n",
    "\n",
    "ret = fit_classifiers(X_train, y_train, X_test, y_test, \n",
    "                      province_encoder=province_encoder, clf_params=params,\n",
    "                      range_num_words=num_words_to_fit, num_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2500 palabras dan un accuracy de 71%. BASTANTE BIEN. Luego disminuye la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250   palabras ----> accuracy 25.12 mean distance 750.3752\n",
      "500   palabras ----> accuracy 31.92 mean distance 676.392\n",
      "750   palabras ----> accuracy 35.24 mean distance 643.978\n",
      "1000  palabras ----> accuracy 38.56 mean distance 614.062\n",
      "1250  palabras ----> accuracy 44.24 mean distance 568.6348\n",
      "1500  palabras ----> accuracy 49.32 mean distance 516.4276\n",
      "1750  palabras ----> accuracy 51.92 mean distance 496.7968\n",
      "2000  palabras ----> accuracy 53.00 mean distance 484.152\n",
      "2250  palabras ----> accuracy 53.72 mean distance 475.3536\n",
      "2500  palabras ----> accuracy 55.08 mean distance 462.016\n",
      "2750  palabras ----> accuracy 57.28 mean distance 438.098\n",
      "3000  palabras ----> accuracy 59.12 mean distance 424.4572\n",
      "3250  palabras ----> accuracy 60.12 mean distance 419.0848\n",
      "3500  palabras ----> accuracy 60.68 mean distance 411.8884\n",
      "3750  palabras ----> accuracy 61.00 mean distance 402.1748\n",
      "4000  palabras ----> accuracy 61.28 mean distance 396.7428\n",
      "4250  palabras ----> accuracy 63.44 mean distance 352.6272\n",
      "4500  palabras ----> accuracy 64.20 mean distance 344.946\n",
      "4750  palabras ----> accuracy 65.52 mean distance 361.4596\n",
      "5000  palabras ----> accuracy 65.44 mean distance 363.3788\n",
      "5500  palabras ----> accuracy 65.40 mean distance 363.0488\n",
      "6000  palabras ----> accuracy 67.40 mean distance 325.9384\n",
      "6500  palabras ----> accuracy 67.52 mean distance 320.4984\n",
      "7000  palabras ----> accuracy 67.52 mean distance 319.4756\n",
      "7500  palabras ----> accuracy 67.52 mean distance 316.7936\n",
      "8000  palabras ----> accuracy 67.64 mean distance 315.458\n",
      "8500  palabras ----> accuracy 68.24 mean distance 282.8416\n",
      "9000  palabras ----> accuracy 68.40 mean distance 280.7088\n",
      "9500  palabras ----> accuracy 68.44 mean distance 280.7484\n",
      "10000 palabras ----> accuracy 68.44 mean distance 281.9068\n",
      "10500 palabras ----> accuracy 68.48 mean distance 281.9504\n",
      "11000 palabras ----> accuracy 68.56 mean distance 282.1152\n",
      "11500 palabras ----> accuracy 69.36 mean distance 272.6472\n",
      "12000 palabras ----> accuracy 69.60 mean distance 272.0088\n",
      "12500 palabras ----> accuracy 69.80 mean distance 269.2596\n",
      "13000 palabras ----> accuracy 69.80 mean distance 270.3984\n",
      "13500 palabras ----> accuracy 69.84 mean distance 272.1724\n",
      "14000 palabras ----> accuracy 69.88 mean distance 272.28\n",
      "14500 palabras ----> accuracy 69.92 mean distance 270.7404\n",
      "15000 palabras ----> accuracy 69.92 mean distance 271.1168\n",
      "15500 palabras ----> accuracy 69.80 mean distance 272.006\n",
      "16000 palabras ----> accuracy 69.72 mean distance 270.9292\n",
      "16500 palabras ----> accuracy 70.08 mean distance 270.608\n",
      "17000 palabras ----> accuracy 70.12 mean distance 270.9364\n",
      "17500 palabras ----> accuracy 70.08 mean distance 273.1564\n",
      "18000 palabras ----> accuracy 70.16 mean distance 270.6296\n",
      "18500 palabras ----> accuracy 70.20 mean distance 271.2784\n",
      "19000 palabras ----> accuracy 70.36 mean distance 270.8848\n",
      "19500 palabras ----> accuracy 70.32 mean distance 270.548\n"
     ]
    }
   ],
   "source": [
    "for r in ret:\n",
    "    num_words = r[\"num_words\"]\n",
    "    acc = r[\"accuracy\"]\n",
    "    md = r[\"mean_distance\"]\n",
    "    print(\"{:<5} palabras ----> accuracy {:.2f} mean distance {}\".format(\n",
    "        num_words, acc*100, md\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(ret, open(\"res_tf_ipf.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 19500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ret = pickle.load(open(\"res_tf_ipf.pkl\", \"rb\"))\n",
    "\n",
    "clf = new_ret[-1][\"clf\"]\n",
    "\n",
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
