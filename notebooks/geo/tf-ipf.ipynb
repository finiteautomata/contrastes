{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geolocalización con TF-IPF\n",
    "\n",
    "En esta notebook haremos un intento de geolocalización con los textos de los usuarios.\n",
    "\n",
    "Pero haremos algo distinto: usaremos Term Frequency - Inverse Province Frequency (TF-IPF)\n",
    "\n",
    "\n",
    "[Geolocation prediction in social media data by finding location indicative words](http://www.aclweb.org/anthology/C12-1064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_json(\"../data/geoloc/users_train.json\")\n",
    "df_test = pd.read_json(\"../data/geoloc/users_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo siguiente:\n",
    "\n",
    "- Entrenemos con unigramas una regresión logística para \n",
    "- Luego probemos con los regionalismos\n",
    "\n",
    "Primero, partamos en train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provincia</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buenosaires</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catamarca</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chaco</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chubut</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cordoba</th>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corrientes</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrerios</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formosa</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jujuy</th>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lapampa</th>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larioja</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mendoza</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misiones</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuquen</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rionegro</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salta</th>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanjuan</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanluis</th>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santacruz</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santafe</th>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santiago</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tierradelfuego</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tucuman</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "provincia           \n",
       "buenosaires      337\n",
       "catamarca        341\n",
       "chaco            331\n",
       "chubut           328\n",
       "cordoba          317\n",
       "corrientes       345\n",
       "entrerios        338\n",
       "formosa          286\n",
       "jujuy            339\n",
       "lapampa          324\n",
       "larioja          306\n",
       "mendoza          326\n",
       "misiones         327\n",
       "neuquen          350\n",
       "rionegro         313\n",
       "salta            346\n",
       "sanjuan          326\n",
       "sanluis          321\n",
       "santacruz        288\n",
       "santafe          347\n",
       "santiago         294\n",
       "tierradelfuego   332\n",
       "tucuman          338"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"provincia\").count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras precalculadas\n",
    "\n",
    "Carguemos antes las palabras que sabemos que ocurren una cantidad razonable de veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 180 ms, total: 1.28 s\n",
      "Wall time: 1.62 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/projects/contrastes/contrastes/processing.py:185: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_palabras = cant_palabras\n",
      "/home/jmperez/projects/contrastes/contrastes/processing.py:186: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.columnas_personas = cant_personas\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.processing import build_dataframe_from_users\n",
    "from contrastes.processing import preprocess_raw_df\n",
    "\n",
    "\n",
    "#word_df = build_dataframe_from_users(row for index, row in df_train.iterrows())\n",
    "\n",
    "word_df = pd.read_csv(\"train_word_df_filtered.csv\", index_col=0)\n",
    "word_df = preprocess_raw_df(word_df, filter_words=(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_palabra</th>\n",
       "      <th>cant_provincias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tiemposur</th>\n",
       "      <td>883.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logroño</th>\n",
       "      <td>711.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nihuil</th>\n",
       "      <td>450.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chivil</th>\n",
       "      <td>332.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipauss</th>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vallerga</th>\n",
       "      <td>291.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asprodema</th>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdelu</th>\n",
       "      <td>244.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calahorra</th>\n",
       "      <td>216.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canicross</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cant_palabra  cant_provincias\n",
       "tiemposur         883.0                1\n",
       "logroño           711.0                1\n",
       "nihuil            450.0                1\n",
       "chivil            332.0                1\n",
       "ipauss            315.0                1\n",
       "vallerga          291.0                1\n",
       "asprodema         290.0                1\n",
       "cdelu             244.0                1\n",
       "calahorra         216.0                1\n",
       "canicross         202.0                1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.sort_values([\"cant_provincias\", \"cant_palabra\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "word_df.iloc[:10][[\"cant_palabra\", \"cant_provincias\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué performance tiene usando 1000, 2000, 3000, y así..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing\n",
      "CPU times: user 9min 35s, sys: 836 ms, total: 9min 36s\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from contrastes.text import tokenize\n",
    "\n",
    "liw_vectorizer = CountVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    vocabulary=word_df.index)\n",
    "\n",
    "X_train = liw_vectorizer.fit_transform(df_train[\"text\"])\n",
    "print(\"Vectorizing\")\n",
    "X_test = liw_vectorizer.transform(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya las tenemos vectorizadas en el orden esperado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "province_encoder = LabelEncoder()\n",
    "\n",
    "province_encoder.fit(df_train[\"provincia\"].values)\n",
    "\n",
    "y_train = province_encoder.transform(df_train[\"provincia\"].values)\n",
    "y_test = province_encoder.transform(df_test[\"provincia\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con 250 palabras\n",
      "Entrenando con 3750 palabras\n",
      "Entrenando con 3250 palabras\n",
      "Entrenando con 2250 palabras\n",
      "Entrenando con 1250 palabras\n",
      "Entrenando con 1750 palabras\n",
      "Entrenando con 750 palabras\n",
      "Entrenando con 2750 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250   palabras ----> accuracy 23.20 mean distance 892.8596\n",
      "Entrenando con 500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750   palabras ----> accuracy 33.52 mean distance 772.9668\n",
      "Entrenando con 1000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250  palabras ----> accuracy 42.68 mean distance 652.8676\n",
      "Entrenando con 1500 palabras\n",
      "1750  palabras ----> accuracy 49.72 mean distance 566.3372\n",
      "Entrenando con 2000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750  palabras ----> accuracy 56.44 mean distance 447.7888\n",
      "Entrenando con 3000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250  palabras ----> accuracy 51.40 mean distance 545.232\n",
      "Entrenando con 2500 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750  palabras ----> accuracy 60.12 mean distance 414.0228\n",
      "Entrenando con 4000 palabras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/contrastes/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250  palabras ----> accuracy 59.32 mean distance 429.2428\n",
      "Entrenando con 3500 palabras\n",
      "500   palabras ----> accuracy 30.12 mean distance 815.73\n",
      "Entrenando con 4250 palabras\n",
      "1000  palabras ----> accuracy 36.88 mean distance 729.8344\n",
      "Entrenando con 4750 palabras\n",
      "1500  palabras ----> accuracy 47.44 mean distance 592.1148\n",
      "Entrenando con 5500 palabras\n",
      "2000  palabras ----> accuracy 50.60 mean distance 555.0476\n",
      "Entrenando con 6500 palabras\n",
      "2500  palabras ----> accuracy 53.12 mean distance 523.9244\n",
      "Entrenando con 7500 palabras\n",
      "3000  palabras ----> accuracy 58.28 mean distance 436.4284\n",
      "Entrenando con 8500 palabras\n",
      "4000  palabras ----> accuracy 60.44 mean distance 408.2564\n",
      "Entrenando con 9500 palabras\n",
      "3500  palabras ----> accuracy 59.76 mean distance 422.914\n",
      "Entrenando con 10500 palabras\n",
      "4250  palabras ----> accuracy 62.04 mean distance 346.054\n",
      "Entrenando con 4500 palabras\n",
      "4750  palabras ----> accuracy 64.04 mean distance 330.8656\n",
      "Entrenando con 5000 palabras\n",
      "5500  palabras ----> accuracy 63.92 mean distance 334.9024\n",
      "Entrenando con 6000 palabras\n",
      "6500  palabras ----> accuracy 65.52 mean distance 305.6924\n",
      "Entrenando con 7000 palabras\n",
      "7500  palabras ----> accuracy 65.92 mean distance 305.4256\n",
      "Entrenando con 8000 palabras\n",
      "8500  palabras ----> accuracy 67.56 mean distance 323.8012\n",
      "Entrenando con 9000 palabras\n",
      "9500  palabras ----> accuracy 67.64 mean distance 321.6164\n",
      "Entrenando con 10000 palabras\n",
      "4500  palabras ----> accuracy 62.96 mean distance 339.8716\n",
      "Entrenando con 11500 palabras\n",
      "10500 palabras ----> accuracy 67.68 mean distance 320.7136\n",
      "Entrenando con 11000 palabras\n",
      "5000  palabras ----> accuracy 63.96 mean distance 334.3492\n",
      "Entrenando con 12500 palabras\n",
      "6000  palabras ----> accuracy 65.44 mean distance 308.2536\n",
      "Entrenando con 13500 palabras\n",
      "7000  palabras ----> accuracy 65.88 mean distance 305.9116\n",
      "Entrenando con 14500 palabras\n",
      "8000  palabras ----> accuracy 66.08 mean distance 307.3648\n",
      "Entrenando con 15500 palabras\n",
      "9000  palabras ----> accuracy 67.56 mean distance 322.9008\n",
      "Entrenando con 16500 palabras\n",
      "10000 palabras ----> accuracy 67.56 mean distance 324.1692\n",
      "Entrenando con 17500 palabras\n",
      "11500 palabras ----> accuracy 68.36 mean distance 312.276\n",
      "Entrenando con 12000 palabras\n",
      "11000 palabras ----> accuracy 67.72 mean distance 320.796\n",
      "Entrenando con 18500 palabras\n",
      "12500 palabras ----> accuracy 68.92 mean distance 305.126\n",
      "Entrenando con 13000 palabras\n",
      "13500 palabras ----> accuracy 68.92 mean distance 305.1184\n",
      "Entrenando con 14000 palabras\n",
      "14500 palabras ----> accuracy 68.88 mean distance 305.63\n",
      "Entrenando con 15000 palabras\n",
      "15500 palabras ----> accuracy 68.84 mean distance 304.5276\n",
      "Entrenando con 16000 palabras\n",
      "12000 palabras ----> accuracy 68.84 mean distance 305.9524\n",
      "Entrenando con 19500 palabras\n",
      "16500 palabras ----> accuracy 69.04 mean distance 297.2956\n",
      "Entrenando con 17000 palabras\n",
      "13000 palabras ----> accuracy 69.00 mean distance 304.568\n",
      "17500 palabras ----> accuracy 69.08 mean distance 298.3096\n",
      "Entrenando con 18000 palabras\n",
      "14000 palabras ----> accuracy 68.84 mean distance 306.4376\n",
      "18500 palabras ----> accuracy 69.08 mean distance 298.0976\n",
      "Entrenando con 19000 palabras\n",
      "15000 palabras ----> accuracy 68.96 mean distance 304.7224\n",
      "16000 palabras ----> accuracy 68.92 mean distance 298.5752\n",
      "17000 palabras ----> accuracy 69.20 mean distance 296.852\n",
      "19500 palabras ----> accuracy 69.04 mean distance 298.8136\n",
      "18000 palabras ----> accuracy 69.12 mean distance 296.9964\n",
      "19000 palabras ----> accuracy 69.04 mean distance 299.0796\n",
      "CPU times: user 168 ms, sys: 716 ms, total: 884 ms\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from contrastes.classifiers import fit_classifiers\n",
    "\n",
    "num_words_to_fit = list(range(250, 5000, 250)) + list(range(5000, 20000, 500))\n",
    "\n",
    "ret = fit_classifiers(X_train, y_train, X_test, y_test, \n",
    "                      province_encoder=province_encoder,\n",
    "                      range_num_words=num_words_to_fit, num_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2500 palabras dan un accuracy de 71%. BASTANTE BIEN. Luego disminuye la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250   palabras ----> accuracy 23.20 mean distance 892.8596\n",
      "500   palabras ----> accuracy 30.12 mean distance 815.73\n",
      "750   palabras ----> accuracy 33.52 mean distance 772.9668\n",
      "1000  palabras ----> accuracy 36.88 mean distance 729.8344\n",
      "1250  palabras ----> accuracy 42.68 mean distance 652.8676\n",
      "1500  palabras ----> accuracy 47.44 mean distance 592.1148\n",
      "1750  palabras ----> accuracy 49.72 mean distance 566.3372\n",
      "2000  palabras ----> accuracy 50.60 mean distance 555.0476\n",
      "2250  palabras ----> accuracy 51.40 mean distance 545.232\n",
      "2500  palabras ----> accuracy 53.12 mean distance 523.9244\n",
      "2750  palabras ----> accuracy 56.44 mean distance 447.7888\n",
      "3000  palabras ----> accuracy 58.28 mean distance 436.4284\n",
      "3250  palabras ----> accuracy 59.32 mean distance 429.2428\n",
      "3500  palabras ----> accuracy 59.76 mean distance 422.914\n",
      "3750  palabras ----> accuracy 60.12 mean distance 414.0228\n",
      "4000  palabras ----> accuracy 60.44 mean distance 408.2564\n",
      "4250  palabras ----> accuracy 62.04 mean distance 346.054\n",
      "4500  palabras ----> accuracy 62.96 mean distance 339.8716\n",
      "4750  palabras ----> accuracy 64.04 mean distance 330.8656\n",
      "5000  palabras ----> accuracy 63.96 mean distance 334.3492\n",
      "5500  palabras ----> accuracy 63.92 mean distance 334.9024\n",
      "6000  palabras ----> accuracy 65.44 mean distance 308.2536\n",
      "6500  palabras ----> accuracy 65.52 mean distance 305.6924\n",
      "7000  palabras ----> accuracy 65.88 mean distance 305.9116\n",
      "7500  palabras ----> accuracy 65.92 mean distance 305.4256\n",
      "8000  palabras ----> accuracy 66.08 mean distance 307.3648\n",
      "8500  palabras ----> accuracy 67.56 mean distance 323.8012\n",
      "9000  palabras ----> accuracy 67.56 mean distance 322.9008\n",
      "9500  palabras ----> accuracy 67.64 mean distance 321.6164\n",
      "10000 palabras ----> accuracy 67.56 mean distance 324.1692\n",
      "10500 palabras ----> accuracy 67.68 mean distance 320.7136\n",
      "11000 palabras ----> accuracy 67.72 mean distance 320.796\n",
      "11500 palabras ----> accuracy 68.36 mean distance 312.276\n",
      "12000 palabras ----> accuracy 68.84 mean distance 305.9524\n",
      "12500 palabras ----> accuracy 68.92 mean distance 305.126\n",
      "13000 palabras ----> accuracy 69.00 mean distance 304.568\n",
      "13500 palabras ----> accuracy 68.92 mean distance 305.1184\n",
      "14000 palabras ----> accuracy 68.84 mean distance 306.4376\n",
      "14500 palabras ----> accuracy 68.88 mean distance 305.63\n",
      "15000 palabras ----> accuracy 68.96 mean distance 304.7224\n",
      "15500 palabras ----> accuracy 68.84 mean distance 304.5276\n",
      "16000 palabras ----> accuracy 68.92 mean distance 298.5752\n",
      "16500 palabras ----> accuracy 69.04 mean distance 297.2956\n",
      "17000 palabras ----> accuracy 69.20 mean distance 296.852\n",
      "17500 palabras ----> accuracy 69.08 mean distance 298.3096\n",
      "18000 palabras ----> accuracy 69.12 mean distance 296.9964\n",
      "18500 palabras ----> accuracy 69.08 mean distance 298.0976\n",
      "19000 palabras ----> accuracy 69.04 mean distance 299.0796\n",
      "19500 palabras ----> accuracy 69.04 mean distance 298.8136\n"
     ]
    }
   ],
   "source": [
    "for r in ret:\n",
    "    num_words = r[\"num_words\"]\n",
    "    acc = r[\"accuracy\"]\n",
    "    md = r[\"mean_distance\"]\n",
    "    print(\"{:<5} palabras ----> accuracy {:.2f} mean distance {}\".format(\n",
    "        num_words, acc*100, md\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(ret, open(\"res_tf_ipf.pkl\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
