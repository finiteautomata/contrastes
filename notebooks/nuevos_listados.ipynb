{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuevos listados\n",
    "\n",
    "En esta notebook, vamos a generar los nuevos listados de palabras..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "analizadas = pd.read_csv(\"data/listado_definitivo.csv\")\n",
    "analizadas.set_index(' ', inplace=True)\n",
    "analizadas[\"candidata\"] = analizadas[\"Palabra Candidata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 5014 palabras analizadas\n"
     ]
    }
   ],
   "source": [
    "palabras_ya_analizadas = analizadas[analizadas['candidata'].notna()]\n",
    "\n",
    "print(\"Tenemos {} palabras analizadas\".format(palabras_ya_analizadas.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listado de Palabras\n",
    "\n",
    "Vamos a regenerar el listado completo de palabras. Y calculemos cuánto falta trabajar si hacemos de nuevo los cálculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df = pd.read_csv(\"data/cantidades_filtradas.csv\", index_col=0)\n",
    "df = df[df.cantUsuariosTotal >= 5]\n",
    "\n",
    "cant_palabras = [c for c in df.columns if re.match(r'.*Palabras$', c)]\n",
    "cant_personas = [c for c in df.columns if re.match(r'.*Usuarios$', c)]\n",
    "\n",
    "df[\"cant_provincias\"] = (df[cant_palabras] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos el valor de la información de cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "df[\"entropy_palabras\"] = df[cant_palabras].apply(entropy, axis=1, raw=True)\n",
    "df[\"entropy_personas\"] = df[cant_personas].apply(entropy, axis=1, raw=True)\n",
    "\n",
    "df[\"delta_palabras\"] = np.log2(23) - df[\"entropy_palabras\"]\n",
    "df[\"delta_personas\"] = np.log2(23) - df[\"entropy_personas\"]\n",
    "\n",
    "df[\"log_cantidad\"] = np.log2(df.cantPalabra)\n",
    "df[\"log_personas\"] = np.log2(df.cantUsuariosTotal)\n",
    "\n",
    "df[\"norm_cantidad\"] = df[\"log_cantidad\"] / df[\"log_cantidad\"].max() \n",
    "df[\"norm_personas\"] = df[\"log_personas\"] / df[\"log_personas\"].max()\n",
    "\n",
    "df[\"ival_palabras\"] = df.norm_cantidad * df.delta_palabras\n",
    "df[\"ival_personas\"] = df.norm_personas * df.delta_personas\n",
    "\n",
    "\n",
    "df[\"ival\"] = df[\"ival_palabras\"] * df[\"ival_personas\"]\n",
    "df[\"ival_norm\"] = (1+df[\"ival_palabras\"]) * (1+df[\"ival_personas\"])\n",
    "\n",
    "df_personas = df.sort_values(\"ival_personas\", ascending=False)\n",
    "df_palabras = df.sort_values(\"ival_palabras\", ascending=False)\n",
    "df_pp = df.sort_values(\"ival\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos ligeramente el cálculo de la normalización y del IV, contemplando el orden de personas\n",
    "\n",
    "¿De las primeras 1000, cuántas no están en las ya analizadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_porcentaje_candidatas(palabras):\n",
    "    subconj_analizado = palabras.index.intersection(palabras_ya_analizadas.index)\n",
    "    candidatas = (analizadas.loc[subconj_analizado]['candidata'] != '0').sum()\n",
    "    total = subconj_analizado.shape[0]\n",
    "    print(\"Palabras candidatas = {}\".format(candidatas))\n",
    "    print(\"Total analizadas actualmente = {}\".format(total))\n",
    "    \n",
    "    return candidatas / total\n",
    "\n",
    "def analizar_palabras_restantes(n, dataframes):\n",
    "    total = 0\n",
    "    todas_las_palabras = set()\n",
    "    print(\"=\"* 80)\n",
    "    print(\"Primeras {} palabras\".format(n))\n",
    "    \n",
    "    for nombre, this_df in dataframes.items(): \n",
    "        print('#'*40)\n",
    "        print(\"Métrica: {}\".format(nombre))\n",
    "        palabras = this_df.iloc[:n]\n",
    "        \n",
    "        metrica = calcular_porcentaje_candidatas(palabras)\n",
    "        restantes = {p for p in palabras.index if p not in palabras_ya_analizadas.index}\n",
    "        total+=len(restantes)\n",
    "        todas_las_palabras = todas_las_palabras.union(restantes)\n",
    "        print(\"Faltan etiquetar {} palabras\".format(len(restantes)))\n",
    "        print(\"Porcentaje candidatas = {}\".format(metrica))\n",
    "    print(\"Faltan etiquetar (sin repeticiones) = {}\".format(len(todas_las_palabras)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Primeras 1000 palabras\n",
      "########################################\n",
      "Métrica: Palabras\n",
      "Palabras candidatas = 185\n",
      "Total analizadas actualmente = 821\n",
      "Faltan etiquetar 179 palabras\n",
      "Porcentaje candidatas = 0.22533495736906212\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 309\n",
      "Total analizadas actualmente = 908\n",
      "Faltan etiquetar 92 palabras\n",
      "Porcentaje candidatas = 0.34030837004405284\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 250\n",
      "Total analizadas actualmente = 920\n",
      "Faltan etiquetar 80 palabras\n",
      "Porcentaje candidatas = 0.2717391304347826\n",
      "Faltan etiquetar (sin repeticiones) = 250\n",
      "================================================================================\n",
      "Primeras 5000 palabras\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 795\n",
      "Total analizadas actualmente = 1999\n",
      "Faltan etiquetar 3001 palabras\n",
      "Porcentaje candidatas = 0.39769884942471234\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 843\n",
      "Total analizadas actualmente = 2420\n",
      "Faltan etiquetar 2580 palabras\n",
      "Porcentaje candidatas = 0.34834710743801656\n",
      "Faltan etiquetar (sin repeticiones) = 3232\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Palabras\": df_palabras, \n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp,\n",
    "}\n",
    "analizar_palabras_restantes(1000, dataframes)\n",
    "dataframes = {\n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp,\n",
    "}\n",
    "\n",
    "analizar_palabras_restantes(5000, dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin usar el log(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo de nuevo el dataframe\n",
    "df = pd.read_csv(\"data/cantidades_filtradas.csv\", index_col=0)\n",
    "df = df[df.cantUsuariosTotal >= 2]\n",
    "\n",
    "cant_palabras = [c for c in df.columns if re.match(r'.*Palabras$', c)]\n",
    "cant_personas = [c for c in df.columns if re.match(r'.*Usuarios$', c)]\n",
    "\n",
    "df[\"cant_provincias\"] = (df[cant_palabras] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastes.information_value import simulated_shuffled_entropy_multinomial\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "fn = lambda ws: simulated_shuffled_entropy_multinomial(int(ws), len(cant_palabras))\n",
    "\n",
    "df[\"sh_entropy_palabras\"] = df.cantPalabra.apply(fn)\n",
    "df[\"sh_entropy_personas\"] = df.cantUsuariosTotal.apply(fn)\n",
    "\n",
    "df[\"entropy_palabras\"] = df[cant_palabras].apply(entropy, axis=1, raw=True)\n",
    "df[\"entropy_personas\"] = df[cant_personas].apply(entropy, axis=1, raw=True)\n",
    "\n",
    "df[\"delta_palabras\"] = df[\"sh_entropy_palabras\"] - df[\"entropy_palabras\"]\n",
    "df[\"delta_personas\"] = df[\"sh_entropy_personas\"] - df[\"entropy_personas\"]\n",
    "\n",
    "df[\"log_cantidad\"] = np.log2(df.cantPalabra)\n",
    "df[\"log_personas\"] = np.log2(df.cantUsuariosTotal)\n",
    "\n",
    "df[\"norm_cantidad\"] = df[\"log_cantidad\"] / df[\"log_cantidad\"].max() \n",
    "df[\"norm_personas\"] = df[\"log_personas\"] / df[\"log_personas\"].max()\n",
    "\n",
    "df[\"ival_palabras\"] = df.norm_cantidad * df.delta_palabras\n",
    "df[\"ival_personas\"] = df.norm_personas * df.delta_personas\n",
    "df[\"ival\"] = df[\"ival_palabras\"] * df[\"ival_personas\"]\n",
    "\n",
    "df_personas = df.sort_values(\"ival_personas\", ascending=False)\n",
    "df_palabras = df.sort_values(\"ival_palabras\", ascending=False)\n",
    "df_pp = df.sort_values(\"ival\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Primeras 1000 palabras\n",
      "########################################\n",
      "Métrica: Palabras\n",
      "Palabras candidatas = 151\n",
      "Total analizadas actualmente = 782\n",
      "Faltan etiquetar 218 palabras\n",
      "Porcentaje candidatas = 0.19309462915601022\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 298\n",
      "Total analizadas actualmente = 1000\n",
      "Faltan etiquetar 0 palabras\n",
      "Porcentaje candidatas = 0.298\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 252\n",
      "Total analizadas actualmente = 1000\n",
      "Faltan etiquetar 0 palabras\n",
      "Porcentaje candidatas = 0.252\n",
      "Faltan etiquetar (sin repeticiones) = 218\n",
      "================================================================================\n",
      "Primeras 5000 palabras\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 2094\n",
      "Total analizadas actualmente = 4617\n",
      "Faltan etiquetar 383 palabras\n",
      "Porcentaje candidatas = 0.4535412605588044\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 1902\n",
      "Total analizadas actualmente = 4496\n",
      "Faltan etiquetar 504 palabras\n",
      "Porcentaje candidatas = 0.42304270462633453\n",
      "Faltan etiquetar (sin repeticiones) = 770\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Palabras\": df_palabras, \n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp\n",
    "}\n",
    "analizar_palabras_restantes(1000, dataframes)\n",
    "dataframes = {\n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp,\n",
    "    \n",
    "}\n",
    "\n",
    "analizar_palabras_restantes(5000, dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando cálculo con normalización \"vieja\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo de nuevo el dataframe\n",
    "df = pd.read_csv(\"data/cantidades_filtradas.csv\", index_col=0)\n",
    "df = df[df.cantUsuariosTotal >= 2]\n",
    "\n",
    "cant_palabras = [c for c in df.columns if re.match(r'.*Palabras$', c)]\n",
    "cant_personas = [c for c in df.columns if re.match(r'.*Usuarios$', c)]\n",
    "\n",
    "df[\"cant_provincias\"] = (df[cant_palabras] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastes.information_value import simulated_shuffled_entropy_multinomial\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "fn = lambda ws: simulated_shuffled_entropy_multinomial(int(ws), len(cant_palabras))\n",
    "\n",
    "df[\"sh_entropy_palabras\"] = df.cantPalabra.apply(fn)\n",
    "df[\"sh_entropy_personas\"] = df.cantUsuariosTotal.apply(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"entropy_palabras\"] = df[cant_palabras].apply(entropy, axis=1, raw=True)\n",
    "df[\"entropy_personas\"] = df[cant_personas].apply(entropy, axis=1, raw=True)\n",
    "\n",
    "df[\"delta_palabras\"] = df[\"sh_entropy_palabras\"] - df[\"entropy_palabras\"]\n",
    "df[\"delta_personas\"] = df[\"sh_entropy_personas\"] - df[\"entropy_personas\"]\n",
    "\n",
    "df[\"log_cantidad\"] = np.log2(df.cantPalabra)\n",
    "df[\"log_personas\"] = np.log2(df.cantUsuariosTotal)\n",
    "\n",
    "df[\"norm_cantidad\"] = (df[\"log_cantidad\"] - df[\"log_cantidad\"].min()) \\\n",
    "    / (df[\"log_cantidad\"].max() - df[\"log_cantidad\"].min())\n",
    "df[\"norm_personas\"] = (df[\"log_personas\"] - df[\"log_personas\"].min()) \\\n",
    "    / (df[\"log_personas\"].max() - df[\"log_personas\"].min())\n",
    "\n",
    "df[\"ival_palabras\"] = df.norm_cantidad * df.delta_palabras\n",
    "df[\"ival_personas\"] = df.norm_personas * df.delta_personas\n",
    "\n",
    "\n",
    "df[\"ival\"] = df[\"ival_palabras\"] * df[\"ival_personas\"]\n",
    "\n",
    "df_personas = df.sort_values(\"ival_personas\", ascending=False)\n",
    "df_palabras = df.sort_values(\"ival_palabras\", ascending=False)\n",
    "df_pp = df.sort_values(\"ival\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Primeras 1000 palabras\n",
      "########################################\n",
      "Métrica: Palabras\n",
      "Palabras candidatas = 226\n",
      "Total analizadas actualmente = 772\n",
      "Faltan etiquetar 228 palabras\n",
      "Porcentaje candidatas = 0.2927461139896373\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 315\n",
      "Total analizadas actualmente = 1000\n",
      "Faltan etiquetar 0 palabras\n",
      "Porcentaje candidatas = 0.315\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 296\n",
      "Total analizadas actualmente = 1000\n",
      "Faltan etiquetar 0 palabras\n",
      "Porcentaje candidatas = 0.296\n",
      "Faltan etiquetar (sin repeticiones) = 228\n",
      "================================================================================\n",
      "Primeras 5000 palabras\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 2088\n",
      "Total analizadas actualmente = 4569\n",
      "Faltan etiquetar 431 palabras\n",
      "Porcentaje candidatas = 0.45699277741300065\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 1657\n",
      "Total analizadas actualmente = 3875\n",
      "Faltan etiquetar 1125 palabras\n",
      "Porcentaje candidatas = 0.4276129032258065\n",
      "Faltan etiquetar (sin repeticiones) = 1369\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Palabras\": df_palabras, \n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp\n",
    "}\n",
    "analizar_palabras_restantes(1000, dataframes)\n",
    "dataframes = {\n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp,\n",
    "    \n",
    "}\n",
    "\n",
    "analizar_palabras_restantes(5000, dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando el cálculo viejo CASI idéntico\n",
    "\n",
    "No usó normalización en las dos primeras métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo de nuevo el dataframe\n",
    "df = pd.read_csv(\"data/cantidades_filtradas.csv\", index_col=0)\n",
    "df = df[df.cantUsuariosTotal >= 5]\n",
    "\n",
    "cant_palabras = [c for c in df.columns if re.match(r'.*Palabras$', c)]\n",
    "cant_personas = [c for c in df.columns if re.match(r'.*Usuarios$', c)]\n",
    "\n",
    "df[\"cant_provincias\"] = (df[cant_palabras] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from contrastes.information_value import simulated_shuffled_entropy_multinomial\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "fn = lambda ws: simulated_shuffled_entropy_multinomial(int(ws), len(cant_palabras))\n",
    "\n",
    "\n",
    "df[\"sh_entropy_personas\"] = df.cantUsuariosTotal.apply(fn)\n",
    "df[\"sh_entropy_palabras\"] = df.cantPalabra.apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"entropy_palabras\"] = df[cant_palabras].apply(entropy, axis=1, raw=True)\n",
    "df[\"entropy_personas\"] = df[cant_personas].apply(entropy, axis=1, raw=True)\n",
    "\n",
    "df[\"delta_palabras\"] = df[\"sh_entropy_palabras\"] - df[\"entropy_palabras\"]\n",
    "df[\"delta_personas\"] = df[\"sh_entropy_personas\"] - df[\"entropy_personas\"]\n",
    "\n",
    "df[\"log_cantidad\"] = np.log2(df.cantPalabra)\n",
    "df[\"log_personas\"] = np.log2(df.cantUsuariosTotal)\n",
    "\n",
    "df[\"norm_cantidad\"] = (df[\"log_cantidad\"] - df[\"log_cantidad\"].min()) \\\n",
    "    / (df[\"log_cantidad\"].max() - df[\"log_cantidad\"].min())\n",
    "df[\"norm_personas\"] = (df[\"log_personas\"] - df[\"log_personas\"].min()) \\\n",
    "    / (df[\"log_personas\"].max() - df[\"log_personas\"].min())\n",
    "\n",
    "df[\"ival_palabras\"] = df.log_cantidad * df.delta_palabras\n",
    "df[\"ival_personas\"] = df.log_personas * df.delta_personas\n",
    "df[\"ival\"] = df.norm_cantidad * df.norm_personas * df.delta_palabras * df.delta_personas\n",
    "\n",
    "df_personas = df.sort_values(\"ival_personas\", ascending=False)\n",
    "df_palabras = df.sort_values(\"ival_palabras\", ascending=False)\n",
    "df_pp = df.sort_values(\"ival\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Primeras 1000 palabras\n",
      "########################################\n",
      "Métrica: Palabras\n",
      "Palabras candidatas = 169\n",
      "Total analizadas actualmente = 857\n",
      "Faltan etiquetar 143 palabras\n",
      "Porcentaje candidatas = 0.1971995332555426\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 293\n",
      "Total analizadas actualmente = 1000\n",
      "Faltan etiquetar 0 palabras\n",
      "Porcentaje candidatas = 0.293\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 313\n",
      "Total analizadas actualmente = 998\n",
      "Faltan etiquetar 2 palabras\n",
      "Porcentaje candidatas = 0.313627254509018\n",
      "Faltan etiquetar (sin repeticiones) = 144\n",
      "================================================================================\n",
      "Primeras 5000 palabras\n",
      "########################################\n",
      "Métrica: Personas\n",
      "Palabras candidatas = 2087\n",
      "Total analizadas actualmente = 4621\n",
      "Faltan etiquetar 379 palabras\n",
      "Porcentaje candidatas = 0.4516338454879896\n",
      "########################################\n",
      "Métrica: PalPer\n",
      "Palabras candidatas = 1647\n",
      "Total analizadas actualmente = 3783\n",
      "Faltan etiquetar 1217 palabras\n",
      "Porcentaje candidatas = 0.43536875495638383\n",
      "Faltan etiquetar (sin repeticiones) = 1461\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    \"Palabras\": df_palabras, \n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp\n",
    "}\n",
    "analizar_palabras_restantes(1000, dataframes)\n",
    "dataframes = {\n",
    "    \"Personas\": df_personas, \n",
    "    \"PalPer\": df_pp,\n",
    "    \n",
    "}\n",
    "\n",
    "analizar_palabras_restantes(5000, dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
